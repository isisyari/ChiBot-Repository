{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Excel file...\n",
      "Successfully read Excel file with 15 rows and 25 columns\n",
      "Field names: ['Title', 'Descriptive Text', 'Creator (Photographer)', 'Source', 'Bibliography', 'Author of Text', 'Hyperlinked Terms Associated', 'Historical Sources Associated (Title, Source, and Link)', 'Location markers (lat/long)', 'neighborhood names associated', 'Street addresses associated', 'time periods (YYYY-YYYY)', 'Keywords associated with the Chicago Collections Consortium', 'Table?']\n",
      "Created vacation_spots_1.json\n",
      "Created valparaiso_university_2.json\n",
      "Created valparaiso__in_3.json\n",
      "Created vaudeville_4.json\n",
      "Created veluchamy_enterprises_5.json\n",
      "Created venezuelans_6.json\n",
      "Created vernon_hills__il_7.json\n",
      "Created veterans__hospitals_8.json\n",
      "Created vice_commissions_9.json\n",
      "Created vice_districts_10.json\n",
      "Created victims_of_the_january_1909_68th_street_water_intake_crib_disaster_11.json\n",
      "Created victor_adding_machine_co._12.json\n",
      "Created vietnamese_13.json\n",
      "Created view_east_toward_buckingham_fountain_and_lake_michigan__1959_14.json\n",
      "Created view_north_along_the_chicago_river__2004_15.json\n",
      "Created view_west_on_congress_parkway_from_columbus_drive__2004_16.json\n",
      "Created view_of_chicago_before_fire_of_1871_17.json\n",
      "Created view_of_dusable_s_cabin_18.json\n",
      "Created villa_district_19.json\n",
      "Created villa_park__il_20.json\n",
      "Created vice_districts_21.json\n",
      "Created virgil__il_22.json\n",
      "Created visitation_and_aid_society_23.json\n",
      "Created volo__il_24.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "def clean_string(s):\n",
    "    # Remove control characters and clean up whitespace\n",
    "    if pd.notna(s):\n",
    "        return re.sub(r'[\\x00-\\x1F\\x7F]', '', str(s)).strip()\n",
    "    return \"\"\n",
    "\n",
    "def format_array(value):\n",
    "    if pd.isna(value):\n",
    "        return []\n",
    "    items = [clean_string(item) for item in str(value).replace(\"'\", \"\").split('|')]\n",
    "    return [item for item in items if item]\n",
    "\n",
    "def safe_filename(name):\n",
    "    return re.sub(r'[^\\w\\-.]', '_', name.lower().replace(' ', '_'))\n",
    "\n",
    "def excel_to_json_files(df, output_dir='output'):\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "    field_names = [name.strip() for name in df.iloc[:, 0] if pd.notna(name)]\n",
    "    print(f\"Field names: {field_names}\")  # Debug\n",
    "\n",
    "    for col_idx in range(1, len(df.columns)):\n",
    "        try:\n",
    "            data_dict = {}\n",
    "            for field, value in zip(field_names, df.iloc[:, col_idx]):\n",
    "                if pd.isna(value):\n",
    "                    continue\n",
    "                if \"Hyperlinked Terms Associated\" in field:\n",
    "                    data_dict[field] = format_array(value)\n",
    "                elif \"Street addresses associated\" in field:\n",
    "                    data_dict[field] = format_array(value)\n",
    "                else:\n",
    "                    data_dict[field] = clean_string(value)\n",
    "\n",
    "            if data_dict.get(\"Title\"):\n",
    "                title = clean_string(data_dict[\"Title\"])\n",
    "                file_name = f\"{safe_filename(title)}_{col_idx}.json\"\n",
    "                file_path = Path(output_dir) / file_name\n",
    "                try:\n",
    "                    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(data_dict, f, indent=4, ensure_ascii=False)\n",
    "                    print(f\"Created {file_name}\")\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Invalid JSON for {title}: {e}\")\n",
    "            else:\n",
    "                print(f\"Column {col_idx}: Missing 'Title', skipping...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in column {col_idx}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    excel_file_path = \"Book15.xlsx\"\n",
    "    output_directory = \"VV\"\n",
    "\n",
    "    try:\n",
    "        print(\"Reading Excel file...\")\n",
    "        df = pd.read_excel(excel_file_path)\n",
    "        print(f\"Successfully read Excel file with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        excel_to_json_files(df, output_dir=output_directory)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {excel_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing column 1: name 'field_names' is not defined\n",
      "Error processing column 2: name 'field_names' is not defined\n"
     ]
    }
   ],
   "source": [
    "for col_idx in range(1, len(df.columns)):\n",
    "    try:\n",
    "        data_dict = {}\n",
    "        for field, value in zip(field_names, df.iloc[:, col_idx]):\n",
    "            if pd.isna(value):\n",
    "                continue\n",
    "            if \"Hyperlinked Terms Associated\" in field:\n",
    "                data_dict[field] = format_array(value)\n",
    "            else:\n",
    "                data_dict[field] = clean_string(value)\n",
    "\n",
    "        # Construct file name\n",
    "        title = clean_string(df.iloc[0, col_idx])  # First row as title\n",
    "        file_name = Path(output_dir) / f\"{title.replace(' ', '_').lower()}.json\"\n",
    "\n",
    "        # Debug log: processing file\n",
    "        print(f\"Processing file: {file_name}...\")\n",
    "\n",
    "        # Always write/overwrite the file\n",
    "        with open(file_name, 'w') as json_file:\n",
    "            json.dump(data_dict, json_file, indent=4)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing column {col_idx}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
